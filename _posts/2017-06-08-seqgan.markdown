---
layout: post
title:  "What's good for the goose is good for the GANder"
date:   2017-06-08 01:27:07 -0700
categories: deep-learning ml project
---

<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

Recently, I took [this course](https://cs224n.stanford.edu) on Natural Language Processing (NLP) and Deep Learning. I learned a lot about different types of neural networks and how they are applied to language models in things we use to communicate in every day (i.e. web search, ads, emails, language translation). For my final project, I thought it would be interesting to tackle neural text generation using a special type of neural network called a Generative Adversarial Network (GAN). GANs have mostly been used in computer vision, for generating photorealistic images or reconstructing images based on a provided sample set of images. For instance, examples like [this](https://twitter.com/goodfellow_ian/status/851124988903997440?lang=en) video of a horse-turned-zebra were created using a GAN. There are also other cool applications of GANs, such as neural style transfer: [this](https://github.com/jcjohnson/neural-style) fairly well-known mapping of the artistic style of [The Starry Night](https://en.wikipedia.org/wiki/The_Starry_Night) painting onto photographs. As you likely have already concluded from these examples, we must first collecting a large amount of data in the interested domain, then training a model (the GAN) to generate similar data. My project partner and I figured that since the data available for the English language is essentially ubiquitous (i.e. [the Penn Treebank](https://web.archive.org/web/19970614160127/http://www.cis.upenn.edu:80/~treebank/) is an annotated text for linguistic structure that already exists), training a model to simulate the linguistic structure of English sentences should be fairly straight-forward.

# But, What is a GAN?

In a nutshell, **Generative Adversarial Nets (GANs)** are a type of generative model used in unsupervised machine learning. To build a GAN, we must build two different neural networks:
1. **Discriminator**: a traditional classification network that *discriminates* inputs as real (a part of the training data) or fake (not a part of the training data)
2. **Generator**: a neural network that transforms random noise input into the desired output

The goal of the generator is to fool the discriminator into thinking that the desired output it produces is real while discriminator tries to correctly classify real vs. fake. In a GAN, we put these two networks together in a constant feedback loop so that both compete against each other in a zero-sum game. Because of the nature of this back and forth process, we model this as a minimax game, described as follows:  

$$
\underset{G}{\text{minimize}}\; \underset{D}{\text{maximize}}\; \mathbb{E}_{x \sim p_\text{data}}\left[\log D(x)\right] + \mathbb{E}_{z \sim p(z)}\left[\log \left(1-D(G(z))\right)\right]
$$

which you can read more about in the original 2014 paper [Goodfellow et al](https://arxiv.org/abs/1406.2661).

In the past, GANs have been pretty successful in computer vision for generating images, but not so much in natural language tasks. One of the many restrictions include that it is very difficult to back-propagate through discrete-value random variables. Imagine backpropagating gradients through discrete numerical indices {1: 'cat', 2: 'dog'}. What word would index 1.0000008 represent?


We took inspiration for our project from the following two papers:
[Sequence GAN](https://arxiv.org/abs/1609.05473)
[Maximum Augmented Likelihood GAN](https://arxiv.org/abs/1702.07983)

# Sequence GAN

Recently, however, GANs have actually been found to perform pretty well on discrete data (words). Sequence GAN ([Yu et al. 2017][seq-gan]) introduces a solution by modeling the data generator as a reinforcement learning (RL) policy to overcome the generator differentiation problem, with the RL reward signals produced by the discriminator after it judges complete sequences.

Because no post is proper without a proper diagram, here is a sketch of what this network looks like (courtesy of [Yu et al. 2017][seq-gan]): 

<div style="text-align: center"><img src="https://raw.githubusercontent.com/LantaoYu/SeqGAN/master/figures/seqgan.png"></div>

However, problems with this model persist, as the GAN training objective is inherently unstable, producing a large variation of results that make it difficult to fool the discriminator. Maximum-likelihood Augmented Discrete GAN ([Che et al. 2017][mali-gan]) suggests a new low-variance objective for the generator. More to be said on this in my next post in this series.

<!---# Maximum Likelihood Augmented Discrete GAN

However, problems with this model persist, as the GAN training objective is inherently unstable, producing a large variation of results that make it difficult to fool the discriminator. Maximum-Likelihood Augmented Discrete GAN (Che at al. 2017) suggests a new low-variance objective for the generator, using a normalized reward signal from the discriminator that corresponds to log-likelihood. Our project explores both proposed implementations: we produce experimental results on both synthetic and real-world discrete datasets to explore the effectiveness of GAN over strong baselines.

# Final Thoughts?

Overall, despite the initially-steep learning curve, I really enjoyed working on this project. It was pretty cool that I got to work on cutting-edge research (and implement papers less than a week after they had been published no less!). 10/10 would definitely do again.-->

[seq-gan]: https://arxiv.org/abs/1609.05473
[mali-gan]: https://arxiv.org/abs/1702.07983
