---
layout: post
title:  "What's good for the goose is good for the GANder: A look into Generative Adversarial Networks for Neural Language Generation"
date:   2017-06-08 01:27:07 -0700
categories: deep-learning ml project
---

<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

Recently, I took [this course](https://cs224n.stanford.edu) on Natural Language Processing (NLP) and Deep Learning. I learned a lot about different types of neural networks and how they are applied to language models in things we use to communicate every day (i.e. web search, ads, emails, language translation). 

For my final project, my project partner and I thought it would be interesting to tackle neural text generation. Generating authentic human language is a significant and worthwhile challenge in Natural Language Processing (NLP)--it has wide-ranging applications from machine translation to summarization to dialogue generation. The standard methodology has been statistical token generation using recurrent neural netowrks (RNNs) with long short-term memory (LSTM) cells via maximum likelihood estimation (MLE)--i.e. maximize the conditional probability of the next token based on the training data. However, there are several shortcomings to this approach. One is exposure bias: during generation, the generator may see partial sequences it has not seen in training. Another is that it tends ot produce boring and statistically-safe predictions, unlike traditional human text. This has actually insprired several projects aimed at generating text indistinguishable from human text, such as the Turing test. Thus, this naturally leads us to the idea of a 2-part model: a generator and a discriminator that simply judges whether a given sentence was human-generated.

# What is a GAN?

GANs have mostly been used in computer vision, for generating photorealistic images or reconstructing images based on a provided sample set of images. For instance, examples like [this video](https://twitter.com/goodfellow_ian/status/851124988903997440?lang=en) of a horse-turned-zebra were created using a GAN. There are also other cool applications of GANs, such as neural style transfer: [this](https://github.com/jcjohnson/neural-style) is a fairly well-known mapping of the artistic style of [The Starry Night](https://en.wikipedia.org/wiki/The_Starry_Night) painting onto photographs. 

More technically, a GAN is a generative model used in unsupervised machine learning (that is, machine learning used to describe hidden structure in data). 

A GAN is actually made up of 2 different neural networks, each of which has its own distinct inputs and outputs:
1. **Discriminator**: A traditional classification network that *discriminates* its inputs as real (a part of the training data) or fake (generated samples that are not a part of the training data).
2. **Generator**: A neural network that *generates* samples that are similar to the training data. More technically speaking, it *transforms* random noise into the desired output that is similar in structure to the input data of the *model*. However, the generator itself takes random noise as input. 

Combining these 2 models, we say that the goal of the generator is to fool the discriminator into thinking that the desired output it produces is "real," while the discriminator tries to correctly classify its inputs as real or fake (generated). In other words, these two networks are put together in a constant feedback loop so that both compete against each other in a zero-sum game, which can be modeled as a minimax game described as follows:  

$$
\underset{G}{\text{minimize}}\; \underset{D}{\text{maximize}}\; \mathbb{E}_{x \sim p_\text{data}}\left[\log D(x)\right] + \mathbb{E}_{z \sim p(z)}\left[\log \left(1-D(G(z))\right)\right]
$$

This concept was first introduced in 2014 in the paper [Goodfellow et al](https://arxiv.org/abs/1406.2661).


However, even though GANs have been pretty successful in computer vision for generating images, they have often failed in natural language tasks. In image generation, gradients are back-propagated from the result of the discriminator through the start of the generator to update both models at the same time. This is possible because images are composed of continuous pixel values. In the case of text data, generated words are discrete words and it is impossible to slightly adjust the value of word with a grdient. (Imagine backpropagating gradients through discrete numerical indices {1: 'cat', 2: 'dog'}. What word would index 1.0000008 represent?)


Instead, a reinforcement strategy must be implemented, using rewards from the discriminator to update the generator's parameters. Recent publications have applied GAN to discrete data with promising results:
  * [Sequence GAN (Yu et al. 2017)](https://arxiv.org/abs/1609.05473) proposes a model that 
  * [Maximum Augmented Likelihood GAN](https://arxiv.org/abs/1702.07983)

# Sequence GAN

Sequence GAN ([Yu et al. 2017][seq-gan]) introduces a solution by modeling the data generator as a reinforcement learning (RL) policy to overcome the generator differentiation problem, with the RL reward signals produced by the discriminator after it judges complete sequences.

Because no post is proper without a proper diagram, here is a sketch of what this network looks like (courtesy of [Yu et al. 2017][seq-gan]): 

<div style="text-align: center"><img src="https://raw.githubusercontent.com/LantaoYu/SeqGAN/master/figures/seqgan.png"></div>

However, problems with this model persist, as the GAN training objective is inherently unstable, producing a large variation of results that make it difficult to fool the discriminator. Maximum-likelihood Augmented Discrete GAN ([Che et al. 2017][mali-gan]) suggests a new low-variance objective for the generator. More to be said on this in my next post in this series.

<!---# Maximum Likelihood Augmented Discrete GAN

However, problems with this model persist, as the GAN training objective is inherently unstable, producing a large variation of results that make it difficult to fool the discriminator. Maximum-Likelihood Augmented Discrete GAN (Che at al. 2017) suggests a new low-variance objective for the generator, using a normalized reward signal from the discriminator that corresponds to log-likelihood. Our project explores both proposed implementations: we produce experimental results on both synthetic and real-world discrete datasets to explore the effectiveness of GAN over strong baselines.

# Final Thoughts?

Overall, despite the initially-steep learning curve, I really enjoyed working on this project. It was pretty cool that I got to work on cutting-edge research (and implement papers less than a week after they had been published no less!). 10/10 would definitely do again.-->

[seq-gan]: https://arxiv.org/abs/1609.05473
[mali-gan]: https://arxiv.org/abs/1702.07983
